{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94fc6ff7-5130-4348-997e-7821b8abfeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import load_img, img_to_array\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense,Input,Dropout,GlobalAveragePooling2D,Flatten,Conv2D,BatchNormalization,Activation,MaxPooling2D\n",
    "from keras.models import Model,Sequential\n",
    "from tensorflow.keras.optimizers import Adam,SGD,RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75205a7e-f118-467c-bcc3-9e8c301122a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydot in c:\\users\\hp\\anaconda3\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: pyparsing>=2.1.4 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pydot) (2.4.7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\Hp\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6981e898-42b7-4f4e-8efc-76d14beb7339",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.vis_utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb337e15-3853-4d99-86ae-01f92d915476",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.compat.v1.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88d3a4cb-e36f-4a3c-b2b5-769e50379175",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(\"images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c3423d4-0d3d-4ade-ba80-8f780a828a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28822 images belonging to 7 classes.\n",
      "Found 7066 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "\n",
    "datagen_train      = ImageDataGenerator()\n",
    "\n",
    "datagen_validation = ImageDataGenerator()\n",
    "\n",
    "train_set      = datagen_train.flow_from_directory(path + \"/train\", target_size=(48, 48), color_mode = \"grayscale\", batch_size=batch_size, class_mode='categorical')\n",
    "validation_set = datagen_validation.flow_from_directory(path + \"/validation\", target_size=(48, 48), color_mode = \"grayscale\", batch_size=batch_size, class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0817484b-2fd3-4cfa-8859-0e1f70fd6834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 48, 48, 64)        640       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 48, 48, 64)       256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " activation (Activation)     (None, 48, 48, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 24, 24, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 24, 24, 64)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 24, 24, 128)       204928    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 24, 24, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 24, 24, 128)       0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 12, 12, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 12, 12, 128)       0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 12, 12, 512)       590336    \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 12, 12, 512)      2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 12, 12, 512)       0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 6, 6, 512)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 6, 6, 512)         0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 6, 6, 512)         2359808   \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 6, 6, 512)        2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 6, 6, 512)         0         \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 3, 3, 512)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 3, 3, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4608)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               1179904   \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 256)               0         \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 512)               131584    \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 512)               0         \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 7)                 3591      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,478,727\n",
      "Trainable params: 4,474,759\n",
      "Non-trainable params: 3,968\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam,SGD,RMSprop\n",
    "\n",
    "\n",
    "no_of_classes = 7\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "#1st CNN layer\n",
    "model.add(Conv2D(64,(3,3),padding = 'same',input_shape = (48,48,1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "#2nd CNN layer\n",
    "model.add(Conv2D(128,(5,5),padding = 'same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "model.add(Dropout (0.25))\n",
    "\n",
    "#3rd CNN layer\n",
    "model.add(Conv2D(512,(3,3),padding = 'same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "model.add(Dropout (0.25))\n",
    "\n",
    "#4th CNN layer\n",
    "model.add(Conv2D(512,(3,3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "#Fully connected 1st layer\n",
    "model.add(Dense(256))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "# Fully connected layer 2nd layer\n",
    "model.add(Dense(512))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(no_of_classes, activation='softmax'))\n",
    "\n",
    "\n",
    "\n",
    "opt = Adam(learning_rate = 0.001)\n",
    "model.compile(optimizer=opt,loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a8ee05a-44b2-4c5d-bf75-8cdf7d23190e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "440903be-4a9c-4233-97c4-f14951a593f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.4020 - accuracy: 0.8540WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "225/225 [==============================] - 71s 297ms/step - loss: 0.4020 - accuracy: 0.8540 - val_loss: 1.3031 - val_accuracy: 0.6034 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.3779 - accuracy: 0.8612WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "225/225 [==============================] - 36s 159ms/step - loss: 0.3779 - accuracy: 0.8612 - val_loss: 1.3823 - val_accuracy: 0.6036 - lr: 0.0010\n",
      "Epoch 2: early stopping\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"./model.h5\", monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "early_Stopping = EarlyStopping(monitor=\"val_loss\",\n",
    "                              min_delta=0,\n",
    "                              verbose=1,\n",
    "                              restore_best_weights=True)\n",
    "\n",
    "# reduce_learningrate = ReduceLROnPlateau(monitor='val_loss',\n",
    "#                               verbose=1,\n",
    "#                               min_delta=0.001)\n",
    "\n",
    "\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer = Adam(learning_rate=0.001),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_set,\n",
    "                    steps_per_epoch=train_set.n//train_set.batch_size,\n",
    "                    epochs=20,\n",
    "                    validation_data = validation_set,\n",
    "                    validation_steps = validation_set.n//validation_set.batch_size,\n",
    "                    callbacks=callbacks_list\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b6e0fe7c-28ff-4518-aefd-d33fecd75027",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "\n",
    "with open(\"model.json\",\"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b17e0a3b-3327-4c0b-8c7d-c511d9b217df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import model_from_json\n",
    "\n",
    "with open(\"model.json\",\"r\") as json_file:\n",
    "    loaded_model_json = json_file.read()\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "    \n",
    "    loaded_model.load_weights(\"models.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2a345f69-42df-423a-909c-89d74ab51bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56/56 [==============================] - 7s 132ms/step\n"
     ]
    }
   ],
   "source": [
    "prediction = loaded_model.predict(validation_set)[0]\n",
    "labels_emotionals = [\"biasa\", \"marah\", \"mual\", \"sedih\", \"senang\", \"takut\", \"terkejut\"]\n",
    "\n",
    "label = labels_emotionals[prediction.argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "af74cf8d-a0d6-4cce-a383-1ba5136c4358",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sedih'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9f55dc69-5d5a-41ff-a8fc-70ac6d3a458e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.suptitle('Optimizer : Adam', fontsize=10)\n",
    "plt.ylabel('Loss', fontsize=12)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.ylabel('Accuracy', fontsize=12)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "898b4b69-fa04-410c-999b-c88fce03f0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Using VGG-16 Modern Arsitektur\n",
    "\n",
    "vgg_model = tf.keras.applications.VGG16(\n",
    "            weights=\"imagenet\",\n",
    "            input_shape=(48,48,3),\n",
    "            include_top=False\n",
    ")\n",
    "\n",
    "vgg_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ba7165ff-6b9a-47b3-98b0-76ad28c2ea89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create inputs with correct shape\n",
    "inputs = vgg_model.input\n",
    "\n",
    "x = vgg_model(inputs, training=False)\n",
    "\n",
    "# Add pooling layer or flatten layer\n",
    "x = tf.keras.layers.Flatten()(vgg_model.output)\n",
    "\n",
    "# Add final dense layer\n",
    "outputs = tf.keras.layers.Dense(no_of_classes, activation = 'softmax')(x)\n",
    "\n",
    "# Combine inputs and outputs to create model\n",
    "model_vgg_16_params = tf.keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0c1fae33-5d2c-44ef-96f2-cffbad568487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 48, 48, 3)]       0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 48, 48, 64)        1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 48, 48, 64)        36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 24, 24, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 24, 24, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 24, 24, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 12, 12, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 12, 12, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 12, 12, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 12, 12, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 6, 6, 256)         0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 6, 6, 512)         1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 6, 6, 512)         2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 6, 6, 512)         2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 3, 3, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 3, 3, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 3, 3, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 3, 3, 512)         2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 1, 1, 512)         0         \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 7)                 3591      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,718,279\n",
      "Trainable params: 3,591\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_vgg_16_params.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c2c247f2-cbfb-46ca-ae58-284d7625b25d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28822 images belonging to 7 classes.\n",
      "Found 7066 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "\n",
    "datagen_train      = ImageDataGenerator()\n",
    "\n",
    "datagen_validation = ImageDataGenerator()\n",
    "\n",
    "train_set_vgg      = datagen_train.flow_from_directory(path + \"/train\", target_size=(48, 48), color_mode = \"rgb\", batch_size=batch_size, class_mode='categorical')\n",
    "validation_set_vgg = datagen_validation.flow_from_directory(path + \"/validation\", target_size=(48, 48), color_mode = \"rgb\", batch_size=batch_size, class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd8aa1f-6214-4000-8ad6-73d73ba3682e",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath = path+'modelvgg16/'\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "\n",
    "model_vgg_16_params.compile(loss='categorical_crossentropy',metrics=['accuracy'], optimizer='adam')\n",
    "\n",
    "history_vgg16 = model_vgg_16_params.fit(train_set_vgg,\n",
    "          validation_data=validation_set_vgg,\n",
    "          steps_per_epoch=train_set_vgg.samples/train_set_vgg.batch_size,\n",
    "          validation_steps=validation_set_vgg.samples/validation_set_vgg.batch_size,\n",
    "          epochs=20,                           \n",
    "          callbacks=[model_checkpoint_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71b6e31-7e57-4fe8-a650-538108cd49a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import numpy as np\n",
    "#from google.colab import files\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    " \n",
    "img = image.load_img('29.jpg', target_size=(48,48,3))\n",
    "x = image.img_to_array(img)\n",
    "x  = x .flatten()\n",
    "x = np.expand_dims(x, axis=0)\n",
    " \n",
    "images = np.vstack([x])\n",
    "pred = model.predict(images, batch_size=128)\n",
    "pred_digits_number=np.argmax(pred,axis=1)[0]\n",
    "print(pred_digits_number)\n",
    "\n",
    "if pred_digits_number == 1:\n",
    "  print('biasa')\n",
    "elif pred_digits_number == 2:\n",
    "  print('marah')\n",
    "elif pred_digits_number == 3:\n",
    "  print('mual')\n",
    "elif pred_digits_number == 4:\n",
    "  print('sedih')\n",
    "elif pred_digits_number == 5:\n",
    "  print('senang')\n",
    "elif pred_digits_number == 6:\n",
    "  print('takut')\n",
    "elif pred_digits_number == 7:\n",
    "  print('terkejut')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ec647058-363c-458a-8c5f-ffdad3508868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 450ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "(1, 48, 48, 1)\n",
      "1/1 [==============================] - 0s 45ms/step\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19644/2150186415.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mgray\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m     \u001b[0mwajah\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdeteksi_wajah\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetectMultiScale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;32mfor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwajah\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import model_from_json\n",
    "from time import sleep\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing import image\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "deteksi_wajah = cv2.CascadeClassifier('haar.xml')\n",
    "\n",
    "labels_emotionals = [\"biasa\", \"marah\", \"mual\", \"sedih\", \"senang\", \"takut\", \"terkejut\"]\n",
    "\n",
    "with open(\"model.json\",\"r\") as json_file:\n",
    "    loaded_model_json = json_file.read()\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "    \n",
    "    loaded_model.load_weights(\"models.h5\")\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    _, frame = cap.read()\n",
    "\n",
    "    gray  = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    wajah = deteksi_wajah.detectMultiScale(gray)\n",
    "\n",
    "    for(x,y,w,h) in wajah:\n",
    "        cv2.rectangle(frame, (x,y), (x+w, y+h), (0, 255, 255), 2)\n",
    "        roi = gray[y:y+h, x:x+w]\n",
    "        roi = cv2.resize(roi, (48,48), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "        if np.sum([roi]) != 0:\n",
    "            roi_face = roi.astype('float')/255.0\n",
    "            roi_face = img_to_array(roi_face)\n",
    "            roi_face = np.expand_dims(roi_face, axis=0)\n",
    "\n",
    "            prediction = loaded_model.predict(roi_face)[0]\n",
    "\n",
    "            label = labels_emotionals[prediction.argmax()]\n",
    "            label_position = (x, y-10)\n",
    "            cv2.putText(frame, label, label_position, cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,255,0), 2)\n",
    "        else:\n",
    "            cv2.putText(frame, \"tidak terdeteksi\", label_position, cv2.FONT_HERSHEY_SIMPLEX , 1, (0,255,255,0), 2)\n",
    "    cv2.imshow('deteksi expresi wajah', frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xff == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cap.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b987445-fcde-4b9e-9229-470e69c9428e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
