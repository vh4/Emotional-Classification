{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94fc6ff7-5130-4348-997e-7821b8abfeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import load_img, img_to_array\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense,Input,Dropout,GlobalAveragePooling2D,Flatten,Conv2D,BatchNormalization,Activation,MaxPooling2D\n",
    "from keras.models import Model,Sequential\n",
    "from tensorflow.keras.optimizers import Adam,SGD,RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75205a7e-f118-467c-bcc3-9e8c301122a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydot in c:\\users\\hp\\anaconda3\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: pyparsing>=2.1.4 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pydot) (2.4.7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\Hp\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6981e898-42b7-4f4e-8efc-76d14beb7339",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.vis_utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb337e15-3853-4d99-86ae-01f92d915476",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.compat.v1.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88d3a4cb-e36f-4a3c-b2b5-769e50379175",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(\"images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c3423d4-0d3d-4ade-ba80-8f780a828a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28822 images belonging to 7 classes.\n",
      "Found 7066 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "\n",
    "datagen_train      = ImageDataGenerator()\n",
    "\n",
    "datagen_validation = ImageDataGenerator()\n",
    "\n",
    "train_set      = datagen_train.flow_from_directory(path + \"/train\", target_size=(48, 48), color_mode = \"grayscale\", batch_size=batch_size, class_mode='categorical')\n",
    "validation_set = datagen_validation.flow_from_directory(path + \"/validation\", target_size=(48, 48), color_mode = \"grayscale\", batch_size=batch_size, class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0817484b-2fd3-4cfa-8859-0e1f70fd6834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 48, 48, 64)        640       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 48, 48, 64)       256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " activation (Activation)     (None, 48, 48, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 24, 24, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 24, 24, 64)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 24, 24, 128)       204928    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 24, 24, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 24, 24, 128)       0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 12, 12, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 12, 12, 128)       0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 12, 12, 512)       590336    \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 12, 12, 512)      2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 12, 12, 512)       0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 6, 6, 512)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 6, 6, 512)         0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 6, 6, 512)         2359808   \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 6, 6, 512)        2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 6, 6, 512)         0         \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 3, 3, 512)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 3, 3, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4608)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               1179904   \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 256)               0         \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 512)               131584    \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 512)               0         \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 7)                 3591      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,478,727\n",
      "Trainable params: 4,474,759\n",
      "Non-trainable params: 3,968\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam,SGD,RMSprop\n",
    "\n",
    "\n",
    "no_of_classes = 7\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "#1st CNN layer\n",
    "model.add(Conv2D(64,(3,3),padding = 'same',input_shape = (48,48,1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "#2nd CNN layer\n",
    "model.add(Conv2D(128,(5,5),padding = 'same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "model.add(Dropout (0.25))\n",
    "\n",
    "#3rd CNN layer\n",
    "model.add(Conv2D(512,(3,3),padding = 'same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "model.add(Dropout (0.25))\n",
    "\n",
    "#4th CNN layer\n",
    "model.add(Conv2D(512,(3,3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "#Fully connected 1st layer\n",
    "model.add(Dense(256))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "# Fully connected layer 2nd layer\n",
    "model.add(Dense(512))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(no_of_classes, activation='softmax'))\n",
    "\n",
    "\n",
    "\n",
    "opt = Adam(learning_rate = 0.001)\n",
    "model.compile(optimizer=opt,loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a8ee05a-44b2-4c5d-bf75-8cdf7d23190e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "440903be-4a9c-4233-97c4-f14951a593f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "225/225 [==============================] - ETA: 0s - loss: 1.4521 - accuracy: 0.4429WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "225/225 [==============================] - 47s 196ms/step - loss: 1.4521 - accuracy: 0.4429 - val_loss: 1.3101 - val_accuracy: 0.5011 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "225/225 [==============================] - ETA: 0s - loss: 1.2551 - accuracy: 0.5202WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "225/225 [==============================] - 37s 162ms/step - loss: 1.2551 - accuracy: 0.5202 - val_loss: 1.2504 - val_accuracy: 0.5141 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "225/225 [==============================] - ETA: 0s - loss: 1.1713 - accuracy: 0.5544WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "225/225 [==============================] - 36s 161ms/step - loss: 1.1713 - accuracy: 0.5544 - val_loss: 1.1916 - val_accuracy: 0.5467 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "225/225 [==============================] - ETA: 0s - loss: 1.1006 - accuracy: 0.5831WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "225/225 [==============================] - 37s 162ms/step - loss: 1.1006 - accuracy: 0.5831 - val_loss: 1.1874 - val_accuracy: 0.5571 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "225/225 [==============================] - ETA: 0s - loss: 1.0548 - accuracy: 0.6001WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "225/225 [==============================] - 43s 190ms/step - loss: 1.0548 - accuracy: 0.6001 - val_loss: 1.2243 - val_accuracy: 0.5469 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.9996 - accuracy: 0.6256WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "225/225 [==============================] - 37s 164ms/step - loss: 0.9996 - accuracy: 0.6256 - val_loss: 1.0788 - val_accuracy: 0.5923 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.9509 - accuracy: 0.6417WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "225/225 [==============================] - 38s 168ms/step - loss: 0.9509 - accuracy: 0.6417 - val_loss: 1.1389 - val_accuracy: 0.5712 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.9060 - accuracy: 0.6575WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "225/225 [==============================] - 39s 172ms/step - loss: 0.9060 - accuracy: 0.6575 - val_loss: 1.1094 - val_accuracy: 0.5918 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.8556 - accuracy: 0.6761WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "225/225 [==============================] - 37s 164ms/step - loss: 0.8556 - accuracy: 0.6761 - val_loss: 1.0712 - val_accuracy: 0.6119 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.8177 - accuracy: 0.6931WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "225/225 [==============================] - 39s 171ms/step - loss: 0.8177 - accuracy: 0.6931 - val_loss: 1.0912 - val_accuracy: 0.6006 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.7663 - accuracy: 0.7116WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "225/225 [==============================] - 38s 167ms/step - loss: 0.7663 - accuracy: 0.7116 - val_loss: 1.0583 - val_accuracy: 0.6170 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.7169 - accuracy: 0.7317WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "225/225 [==============================] - 42s 187ms/step - loss: 0.7169 - accuracy: 0.7317 - val_loss: 1.0956 - val_accuracy: 0.6142 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.6743 - accuracy: 0.7480WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "225/225 [==============================] - 37s 163ms/step - loss: 0.6743 - accuracy: 0.7480 - val_loss: 1.1072 - val_accuracy: 0.6236 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.6287 - accuracy: 0.7673WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "225/225 [==============================] - 41s 182ms/step - loss: 0.6287 - accuracy: 0.7673 - val_loss: 1.2413 - val_accuracy: 0.5653 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.5945 - accuracy: 0.7794WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "225/225 [==============================] - 44s 196ms/step - loss: 0.5945 - accuracy: 0.7794 - val_loss: 1.2616 - val_accuracy: 0.5756 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.5469 - accuracy: 0.8006WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "225/225 [==============================] - 49s 217ms/step - loss: 0.5469 - accuracy: 0.8006 - val_loss: 1.1514 - val_accuracy: 0.6199 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.5065 - accuracy: 0.8128WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "225/225 [==============================] - 40s 178ms/step - loss: 0.5065 - accuracy: 0.8128 - val_loss: 1.2877 - val_accuracy: 0.5949 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.4842 - accuracy: 0.8209WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "225/225 [==============================] - 42s 188ms/step - loss: 0.4842 - accuracy: 0.8209 - val_loss: 1.3760 - val_accuracy: 0.5557 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.4403 - accuracy: 0.8383WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "225/225 [==============================] - 37s 165ms/step - loss: 0.4403 - accuracy: 0.8383 - val_loss: 1.4746 - val_accuracy: 0.5774 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.4143 - accuracy: 0.8458WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "225/225 [==============================] - 43s 190ms/step - loss: 0.4143 - accuracy: 0.8458 - val_loss: 1.3888 - val_accuracy: 0.5882 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.3883 - accuracy: 0.8594WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "225/225 [==============================] - 38s 167ms/step - loss: 0.3883 - accuracy: 0.8594 - val_loss: 1.2418 - val_accuracy: 0.6244 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.2934 - accuracy: 0.8943WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "225/225 [==============================] - 38s 170ms/step - loss: 0.2934 - accuracy: 0.8943 - val_loss: 1.2243 - val_accuracy: 0.6585 - lr: 1.0000e-04\n",
      "Epoch 23/50\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.2628 - accuracy: 0.9076WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "225/225 [==============================] - 43s 192ms/step - loss: 0.2628 - accuracy: 0.9076 - val_loss: 1.2449 - val_accuracy: 0.6572 - lr: 1.0000e-04\n",
      "Epoch 24/50\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.2493 - accuracy: 0.9115WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "225/225 [==============================] - 37s 164ms/step - loss: 0.2493 - accuracy: 0.9115 - val_loss: 1.2775 - val_accuracy: 0.6562 - lr: 1.0000e-04\n",
      "Epoch 25/50\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.2341 - accuracy: 0.9157WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "225/225 [==============================] - 38s 169ms/step - loss: 0.2341 - accuracy: 0.9157 - val_loss: 1.2915 - val_accuracy: 0.6597 - lr: 1.0000e-04\n",
      "Epoch 26/50\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.2286 - accuracy: 0.9180WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "225/225 [==============================] - 37s 166ms/step - loss: 0.2286 - accuracy: 0.9180 - val_loss: 1.3182 - val_accuracy: 0.6589 - lr: 1.0000e-04\n",
      "Epoch 27/50\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.2228 - accuracy: 0.9212WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "225/225 [==============================] - 37s 165ms/step - loss: 0.2228 - accuracy: 0.9212 - val_loss: 1.3200 - val_accuracy: 0.6595 - lr: 1.0000e-04\n",
      "Epoch 28/50\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.2148 - accuracy: 0.9237WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "225/225 [==============================] - 37s 165ms/step - loss: 0.2148 - accuracy: 0.9237 - val_loss: 1.3508 - val_accuracy: 0.6581 - lr: 1.0000e-04\n",
      "Epoch 29/50\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.2063 - accuracy: 0.9265WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "225/225 [==============================] - 38s 169ms/step - loss: 0.2063 - accuracy: 0.9265 - val_loss: 1.3696 - val_accuracy: 0.6605 - lr: 1.0000e-04\n",
      "Epoch 30/50\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1999 - accuracy: 0.9270WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "225/225 [==============================] - 37s 164ms/step - loss: 0.1999 - accuracy: 0.9270 - val_loss: 1.3614 - val_accuracy: 0.6618 - lr: 1.0000e-04\n",
      "Epoch 31/50\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1924 - accuracy: 0.9294WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "225/225 [==============================] - 37s 163ms/step - loss: 0.1924 - accuracy: 0.9294 - val_loss: 1.3929 - val_accuracy: 0.6574 - lr: 1.0000e-04\n",
      "Epoch 32/50\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1857 - accuracy: 0.9326WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "225/225 [==============================] - 37s 166ms/step - loss: 0.1857 - accuracy: 0.9326 - val_loss: 1.3971 - val_accuracy: 0.6643 - lr: 1.0000e-05\n",
      "Epoch 33/50\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1833 - accuracy: 0.9351WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "225/225 [==============================] - 38s 170ms/step - loss: 0.1833 - accuracy: 0.9351 - val_loss: 1.3963 - val_accuracy: 0.6653 - lr: 1.0000e-05\n",
      "Epoch 34/50\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1880 - accuracy: 0.9335WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "225/225 [==============================] - 37s 164ms/step - loss: 0.1880 - accuracy: 0.9335 - val_loss: 1.3942 - val_accuracy: 0.6646 - lr: 1.0000e-05\n",
      "Epoch 35/50\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1814 - accuracy: 0.9348WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "225/225 [==============================] - 36s 160ms/step - loss: 0.1814 - accuracy: 0.9348 - val_loss: 1.3972 - val_accuracy: 0.6652 - lr: 1.0000e-05\n",
      "Epoch 36/50\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1787 - accuracy: 0.9365WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "225/225 [==============================] - 36s 160ms/step - loss: 0.1787 - accuracy: 0.9365 - val_loss: 1.3991 - val_accuracy: 0.6632 - lr: 1.0000e-05\n",
      "Epoch 37/50\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1767 - accuracy: 0.9366WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "225/225 [==============================] - 36s 161ms/step - loss: 0.1767 - accuracy: 0.9366 - val_loss: 1.3996 - val_accuracy: 0.6642 - lr: 1.0000e-05\n",
      "Epoch 38/50\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1782 - accuracy: 0.9358WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "225/225 [==============================] - 37s 164ms/step - loss: 0.1782 - accuracy: 0.9358 - val_loss: 1.3930 - val_accuracy: 0.6638 - lr: 1.0000e-05\n",
      "Epoch 39/50\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1773 - accuracy: 0.9367WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "225/225 [==============================] - 36s 160ms/step - loss: 0.1773 - accuracy: 0.9367 - val_loss: 1.4057 - val_accuracy: 0.6635 - lr: 1.0000e-05\n",
      "Epoch 40/50\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1781 - accuracy: 0.9369WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "225/225 [==============================] - 37s 165ms/step - loss: 0.1781 - accuracy: 0.9369 - val_loss: 1.4006 - val_accuracy: 0.6653 - lr: 1.0000e-05\n",
      "Epoch 41/50\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1793 - accuracy: 0.9355WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "225/225 [==============================] - 37s 164ms/step - loss: 0.1793 - accuracy: 0.9355 - val_loss: 1.4042 - val_accuracy: 0.6646 - lr: 1.0000e-05\n",
      "Epoch 42/50\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1748 - accuracy: 0.9377WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "225/225 [==============================] - 36s 161ms/step - loss: 0.1748 - accuracy: 0.9377 - val_loss: 1.4035 - val_accuracy: 0.6649 - lr: 1.0000e-06\n",
      "Epoch 43/50\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1711 - accuracy: 0.9388WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "225/225 [==============================] - 36s 160ms/step - loss: 0.1711 - accuracy: 0.9388 - val_loss: 1.4076 - val_accuracy: 0.6648 - lr: 1.0000e-06\n",
      "Epoch 44/50\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1739 - accuracy: 0.9378WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "225/225 [==============================] - 38s 169ms/step - loss: 0.1739 - accuracy: 0.9378 - val_loss: 1.4054 - val_accuracy: 0.6659 - lr: 1.0000e-06\n",
      "Epoch 45/50\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1770 - accuracy: 0.9359WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "225/225 [==============================] - 40s 178ms/step - loss: 0.1770 - accuracy: 0.9359 - val_loss: 1.4061 - val_accuracy: 0.6643 - lr: 1.0000e-06\n",
      "Epoch 46/50\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1769 - accuracy: 0.9374WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "225/225 [==============================] - 48s 215ms/step - loss: 0.1769 - accuracy: 0.9374 - val_loss: 1.4051 - val_accuracy: 0.6639 - lr: 1.0000e-06\n",
      "Epoch 47/50\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1748 - accuracy: 0.9377WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "225/225 [==============================] - 50s 223ms/step - loss: 0.1748 - accuracy: 0.9377 - val_loss: 1.4063 - val_accuracy: 0.6648 - lr: 1.0000e-06\n",
      "Epoch 48/50\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1783 - accuracy: 0.9365WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "225/225 [==============================] - 50s 221ms/step - loss: 0.1783 - accuracy: 0.9365 - val_loss: 1.4070 - val_accuracy: 0.6648 - lr: 1.0000e-06\n",
      "Epoch 49/50\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1731 - accuracy: 0.9379WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "225/225 [==============================] - 65s 287ms/step - loss: 0.1731 - accuracy: 0.9379 - val_loss: 1.4087 - val_accuracy: 0.6651 - lr: 1.0000e-06\n",
      "Epoch 50/50\n",
      "225/225 [==============================] - ETA: 0s - loss: 0.1739 - accuracy: 0.9381WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "225/225 [==============================] - 46s 205ms/step - loss: 0.1739 - accuracy: 0.9381 - val_loss: 1.4057 - val_accuracy: 0.6649 - lr: 1.0000e-06\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"./model.h5\", monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "early_Stopping = EarlyStopping(monitor=\"val_loss\",\n",
    "                              min_delta=0,\n",
    "                              verbose=1,\n",
    "                              restore_best_weights=True)\n",
    "\n",
    "reduce_learningrate = ReduceLROnPlateau(monitor='val_loss',\n",
    "                              verbose=1,\n",
    "                              min_delta=0.001)\n",
    "\n",
    "\n",
    "callbacks_list = [checkpoint,reduce_learningrate]\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer = Adam(learning_rate=0.001),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_set,\n",
    "                    steps_per_epoch=train_set.n//train_set.batch_size,\n",
    "                    epochs=50,\n",
    "                    validation_data = validation_set,\n",
    "                    validation_steps = validation_set.n//validation_set.batch_size,\n",
    "                    callbacks=callbacks_list\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a092fbfc-3c50-42be-a986-e8bb4c8503d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"models.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b6e0fe7c-28ff-4518-aefd-d33fecd75027",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "\n",
    "with open(\"model.json\",\"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b17e0a3b-3327-4c0b-8c7d-c511d9b217df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import model_from_json\n",
    "\n",
    "with open(\"model.json\",\"r\") as json_file:\n",
    "    loaded_model_json = json_file.read()\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "    \n",
    "    loaded_model.load_weights(\"models.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2a345f69-42df-423a-909c-89d74ab51bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56/56 [==============================] - 7s 132ms/step\n"
     ]
    }
   ],
   "source": [
    "prediction = loaded_model.predict(validation_set)[0]\n",
    "labels_emotionals = [\"biasa\", \"marah\", \"mual\", \"sedih\", \"senang\", \"takut\", \"terkejut\"]\n",
    "\n",
    "label = labels_emotionals[prediction.argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "af74cf8d-a0d6-4cce-a383-1ba5136c4358",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sedih'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9f55dc69-5d5a-41ff-a8fc-70ac6d3a458e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.suptitle('Optimizer : Adam', fontsize=10)\n",
    "plt.ylabel('Loss', fontsize=12)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.ylabel('Accuracy', fontsize=12)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "898b4b69-fa04-410c-999b-c88fce03f0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Using VGG-16 Modern Arsitektur\n",
    "\n",
    "vgg_model = tf.keras.applications.VGG16(\n",
    "            weights=\"imagenet\",\n",
    "            input_shape=(48,48,3),\n",
    "            include_top=False\n",
    ")\n",
    "\n",
    "vgg_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ba7165ff-6b9a-47b3-98b0-76ad28c2ea89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create inputs with correct shape\n",
    "inputs = vgg_model.input\n",
    "\n",
    "x = vgg_model(inputs, training=False)\n",
    "\n",
    "# Add pooling layer or flatten layer\n",
    "x = tf.keras.layers.Flatten()(vgg_model.output)\n",
    "\n",
    "# Add final dense layer\n",
    "outputs = tf.keras.layers.Dense(no_of_classes, activation = 'softmax')(x)\n",
    "\n",
    "# Combine inputs and outputs to create model\n",
    "model_vgg_16_params = tf.keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0c1fae33-5d2c-44ef-96f2-cffbad568487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 48, 48, 3)]       0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 48, 48, 64)        1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 48, 48, 64)        36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 24, 24, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 24, 24, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 24, 24, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 12, 12, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 12, 12, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 12, 12, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 12, 12, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 6, 6, 256)         0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 6, 6, 512)         1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 6, 6, 512)         2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 6, 6, 512)         2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 3, 3, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 3, 3, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 3, 3, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 3, 3, 512)         2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 1, 1, 512)         0         \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 7)                 3591      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,718,279\n",
      "Trainable params: 3,591\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_vgg_16_params.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c2c247f2-cbfb-46ca-ae58-284d7625b25d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28822 images belonging to 7 classes.\n",
      "Found 7066 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "\n",
    "datagen_train      = ImageDataGenerator()\n",
    "\n",
    "datagen_validation = ImageDataGenerator()\n",
    "\n",
    "train_set_vgg      = datagen_train.flow_from_directory(path + \"/train\", target_size=(48, 48), color_mode = \"rgb\", batch_size=batch_size, class_mode='categorical')\n",
    "validation_set_vgg = datagen_validation.flow_from_directory(path + \"/validation\", target_size=(48, 48), color_mode = \"rgb\", batch_size=batch_size, class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd8aa1f-6214-4000-8ad6-73d73ba3682e",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath = path+'modelvgg16/'\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "\n",
    "model_vgg_16_params.compile(loss='categorical_crossentropy',metrics=['accuracy'], optimizer='adam')\n",
    "\n",
    "history_vgg16 = model_vgg_16_params.fit(train_set_vgg,\n",
    "          validation_data=validation_set_vgg,\n",
    "          steps_per_epoch=train_set_vgg.samples/train_set_vgg.batch_size,\n",
    "          validation_steps=validation_set_vgg.samples/validation_set_vgg.batch_size,\n",
    "          epochs=20,                           \n",
    "          callbacks=[model_checkpoint_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71b6e31-7e57-4fe8-a650-538108cd49a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import numpy as np\n",
    "#from google.colab import files\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    " \n",
    "img = image.load_img('29.jpg', target_size=(48,48,3))\n",
    "x = image.img_to_array(img)\n",
    "x  = x .flatten()\n",
    "x = np.expand_dims(x, axis=0)\n",
    " \n",
    "images = np.vstack([x])\n",
    "pred = model.predict(images, batch_size=128)\n",
    "pred_digits_number=np.argmax(pred,axis=1)[0]\n",
    "print(pred_digits_number)\n",
    "\n",
    "if pred_digits_number == 1:\n",
    "  print('biasa')\n",
    "elif pred_digits_number == 2:\n",
    "  print('marah')\n",
    "elif pred_digits_number == 3:\n",
    "  print('mual')\n",
    "elif pred_digits_number == 4:\n",
    "  print('sedih')\n",
    "elif pred_digits_number == 5:\n",
    "  print('senang')\n",
    "elif pred_digits_number == 6:\n",
    "  print('takut')\n",
    "elif pred_digits_number == 7:\n",
    "  print('terkejut')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ec647058-363c-458a-8c5f-ffdad3508868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14056/2654703970.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     34\u001b[0m             \u001b[0mroi_face\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroi_face\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m             \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloaded_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroi_face\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m             \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabels_emotionals\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mprediction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   2000\u001b[0m               stacklevel=2)\n\u001b[0;32m   2001\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2002\u001b[1;33m       data_handler = data_adapter.get_data_handler(\n\u001b[0m\u001b[0;32m   2003\u001b[0m           \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2004\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36mget_data_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1399\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"model\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"_cluster_coordinator\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1400\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_ClusterCoordinatorDataHandler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1401\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mDataHandler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1402\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1403\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001b[0m\n\u001b[0;32m   1149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1150\u001b[0m     \u001b[0madapter_cls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1151\u001b[1;33m     self._adapter = adapter_cls(\n\u001b[0m\u001b[0;32m   1152\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1153\u001b[0m         \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[0;32m    290\u001b[0m     \u001b[1;31m# trigger the next permutation. On the other hand, too many simultaneous\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m     \u001b[1;31m# shuffles can contend on a hardware level and degrade all performance.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 292\u001b[1;33m     \u001b[0mindices_dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindices_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprefetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mslice_batch_indices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[1;34m(self, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[0;32m   2046\u001b[0m         warnings.warn(\"The `deterministic` argument has no effect unless the \"\n\u001b[0;32m   2047\u001b[0m                       \"`num_parallel_calls` argument is specified.\")\n\u001b[1;32m-> 2048\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mMapDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreserve_cardinality\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2049\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2050\u001b[0m       return ParallelMapDataset(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, name)\u001b[0m\n\u001b[0;32m   5241\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_use_inter_op_parallelism\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0muse_inter_op_parallelism\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5242\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_preserve_cardinality\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreserve_cardinality\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5243\u001b[1;33m     self._map_func = structured_function.StructuredFunctionWrapper(\n\u001b[0m\u001b[0;32m   5244\u001b[0m         \u001b[0mmap_func\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5245\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_transformation_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[0;32m    269\u001b[0m         \u001b[0mfn_factory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrace_tf_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdefun_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 271\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn_factory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    272\u001b[0m     \u001b[1;31m# There is no graph to add in eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m     \u001b[0madd_to_graph\u001b[0m \u001b[1;33m&=\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mget_concrete_function\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2565\u001b[0m          \u001b[1;32mor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mor\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensorSpec\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2566\u001b[0m     \"\"\"\n\u001b[1;32m-> 2567\u001b[1;33m     graph_function = self._get_concrete_function_garbage_collected(\n\u001b[0m\u001b[0;32m   2568\u001b[0m         *args, **kwargs)\n\u001b[0;32m   2569\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_garbage_collector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2531\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2532\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2533\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2534\u001b[0m       \u001b[0mseen_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2535\u001b[0m       captured = object_identity.ObjectIdentitySet(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2709\u001b[0m             \u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcache_key\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_placeholder_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2710\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2711\u001b[1;33m           \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2712\u001b[0m           self._function_cache.add(cache_key, cache_key_deletion_observer,\n\u001b[0;32m   2713\u001b[0m                                    graph_function)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2625\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2626\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 2627\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   2628\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2629\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1139\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1141\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1143\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    246\u001b[0m           attributes=defun_kwargs)\n\u001b[0;32m    247\u001b[0m       \u001b[1;32mdef\u001b[0m \u001b[0mwrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=missing-docstring\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 248\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwrapper_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    249\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_tensor_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output_structure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py\u001b[0m in \u001b[0;36mwrapper_helper\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    175\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_should_unpack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m         \u001b[0mnested_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 177\u001b[1;33m       \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    178\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0m_should_pack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    687\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 689\u001b[1;33m           \u001b[1;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    690\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    691\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ag_error_metadata'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    375\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    376\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muser_requested\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mconversion\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_allowlisted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 377\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    378\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    379\u001b[0m   \u001b[1;31m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    456\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    457\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 458\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    459\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36mpermutation\u001b[1;34m(_)\u001b[0m\n\u001b[0;32m    281\u001b[0m       \u001b[1;31m# than reusing the same range Tensor. (presumably because of buffer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m       \u001b[1;31m# forwarding.)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 283\u001b[1;33m       \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    284\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"batch\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m         \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1080\u001b[0m       \u001b[1;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1081\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1082\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1083\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1084\u001b[0m         \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mrange\u001b[1;34m(start, limit, delta, dtype, name)\u001b[0m\n\u001b[0;32m   2100\u001b[0m       \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"start\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2101\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlimit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2102\u001b[1;33m       \u001b[0mlimit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlimit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"limit\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2103\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2104\u001b[0m       \u001b[0mdelta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"delta\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\profiler\\trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m           \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 183\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    184\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[0;32m   1638\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1639\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1640\u001b[1;33m       \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1641\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1642\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_conversion_registry.py\u001b[0m in \u001b[0;36m_default_conversion_function\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_default_conversion_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m   \u001b[1;32mdel\u001b[0m \u001b[0mas_ref\u001b[0m  \u001b[1;31m# Unused.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[1;34m(value, dtype, shape, name)\u001b[0m\n\u001b[0;32m    265\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcalled\u001b[0m \u001b[0mon\u001b[0m \u001b[0ma\u001b[0m \u001b[0msymbolic\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m   \"\"\"\n\u001b[1;32m--> 267\u001b[1;33m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0m\u001b[0;32m    268\u001b[0m                         allow_broadcast=True)\n\u001b[0;32m    269\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[1;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[0;32m    287\u001b[0m   \u001b[0mdtype_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtensor_value\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m   \u001b[0mattrs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"value\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtensor_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"dtype\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdtype_value\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 289\u001b[1;33m   const_tensor = g._create_op_internal(  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m    290\u001b[0m       \"Const\", [], [dtype_value.type], attrs=attrs, name=name).outputs[0]\n\u001b[0;32m    291\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m    692\u001b[0m       \u001b[0minp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcapture\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    693\u001b[0m       \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 694\u001b[1;33m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m    695\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    696\u001b[0m         compute_device)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m   3752\u001b[0m     \u001b[1;31m# Session.run call cannot occur between creating and mutating the op.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3753\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mutation_lock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3754\u001b[1;33m       ret = Operation(\n\u001b[0m\u001b[0;32m   3755\u001b[0m           \u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3756\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[0;32m   2127\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mop_def\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2128\u001b[0m         \u001b[0mop_def\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_op_def\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2129\u001b[1;33m       self._c_op = _create_c_op(self._graph, node_def, inputs,\n\u001b[0m\u001b[0;32m   2130\u001b[0m                                 control_input_ops, op_def)\n\u001b[0;32m   2131\u001b[0m       \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[0;32m   1958\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1959\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1960\u001b[1;33m     \u001b[0mc_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1961\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1962\u001b[0m     \u001b[1;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import model_from_json\n",
    "from time import sleep\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing import image\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "deteksi_wajah = cv2.CascadeClassifier('haar.xml')\n",
    "\n",
    "labels_emotionals = [\"biasa\", \"marah\", \"mual\", \"sedih\", \"senang\", \"takut\", \"terkejut\"]\n",
    "\n",
    "with open(\"model.json\",\"r\") as json_file:\n",
    "    loaded_model_json = json_file.read()\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "    \n",
    "    loaded_model.load_weights(\"models.h5\")\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    _, frame = cap.read()\n",
    "\n",
    "    gray  = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    wajah = deteksi_wajah.detectMultiScale(gray)\n",
    "\n",
    "    for(x,y,w,h) in wajah:\n",
    "        cv2.rectangle(frame, (x,y), (x+w, y+h), (0, 255, 255), 2)\n",
    "        roi = gray[y:y+h, x:x+w]\n",
    "        roi = cv2.resize(roi, (48,48), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "        if np.sum([roi]) != 0:\n",
    "            roi_face = roi.astype('float')/255.0\n",
    "            roi_face = img_to_array(roi_face)\n",
    "            roi_face = np.expand_dims(roi_face, axis=0)\n",
    "\n",
    "            prediction = loaded_model.predict(roi_face)[0]\n",
    "\n",
    "            label = labels_emotionals[prediction.argmax()]\n",
    "            label_position = (x, y-10)\n",
    "            cv2.putText(frame, label, label_position, cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,255,0), 2)\n",
    "        else:\n",
    "            cv2.putText(frame, \"tidak terdeteksi\", label_position, cv2.FONT_HERSHEY_SIMPLEX , 1, (0,255,255,0), 2)\n",
    "    cv2.imshow('deteksi expresi wajah', frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xff == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cap.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b987445-fcde-4b9e-9229-470e69c9428e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
